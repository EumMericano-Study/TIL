# AI 
머신러닝의 영역은 다양한 이론들이 존재하고 독립적 이거나/ 유기적으로 연결되어있다.

> 기호주의
> 연결주의
> 진화주의
> 베이스주의
> 유추주의

이 중 딥러닝에 관심이 생겨 딥러닝의 기초가 되는 연결주의에 대해 알아보았다.
## 신경망
> 우리의 두뇌는 어떻게 학습하는가?

### 신경망 ( NN : Neural Network)

**시작**
최초의 시작은 뇌과학의 연결주의이다.
> 연결주의 : 지식이란 신경세포 사이의 연결에 있다.

사람의 뇌는 흔히 1000억개의 뉴런의 연결이라고 한다. 
이는 일직선으로 연결했을때, 지구와 달의 사이의 거리와 비슷한 길이이다.


<img src=./image/1_EarthnMoon.jpg>

이 뉴런들의 연결은 미지의 영역이다. 
이 연결에 대한 가설중 하나가 **헵의 규칙**이다. 


**헵의 규칙**이란 
생물학적인 신경 시스템은 프로그래밍처럼 정해진 input값에 대한 output을 출력하는 것이 아니고, 
지속적인 input 값들이 입력되고, 저장되며 서로 유기적으로 작동하여 계속적인 학습으로 이끌어 낸다는 의미이다.
즉, 뇌에 아주 오래전에 입력된 데이터라 할지라도 현재의 지식에 영향을 미친다는 뜻이다.
<img src=./image/neuron.png>


 기존의 기호주의자 학습에서는 기호와 개념사이에 1:1 대응을 이루었다.
 하지만, 연결주의에서는 한가지의 개념이 여러곳에 흩어져있고,
 단순한 정보를 표현하는데에도 수많은 뉴런들이 사용된다.

>기호주의 : 뉴런의 1:1대응적인 연결
>input : 사각형, 바퀴 4개, 사람보다 큰 크기 
>output : "자동차" 
>
>연결주의 : 뉴런의  유기적인 연결
>input : 시각적 데이터
>output : 대상 물체가 "자동차"일 것이라는 추론


이를 프로그래밍에 적용한것이 **인공신경망**이다

### 인공신경망 ( ANN : Artificial Neural Network)


>기호주의 : input에 대한 output의 Mapping
>input : 사각형, 바퀴 4개, 사람보다 큰 크기 
>output : "자동차" 
>
>연결주의 : 각 Node들의 연결
>input : 시각적 데이터
>output : 대상 물체가 "자동차"일 것이라는 추론

<img src=./image/ANN.png>


우리는 그간 역인역법의 전제에서 목표 결론에 이르기 위해 필요한 규칙을 한 번에 한 단계씩 파악했다. **인공신경망**에서는 이를 동시에 학습한다.

사실, 인공신경망은 완전히 최신화된 이론이 아니다. 
1940년대 맥클럭-피츠 모델을 출발로 오랜기간 연구되어온 한 분야일 뿐이다

초기 인공신경망의 경우,
컴퓨터는 두뇌와 대조적으로 초당 수십억번의 연산을 

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE0NzEzNDcwMywxNTE2MjI2ODgwLC0xMz
Y1NTQ0MiwyNTc5MTIyMTcsLTk3NzUyNzIyMSwtMTg3MDMzODgz
MywtMjAwNzM4Mjk3NiwtNjA2NjcxMjQyLC0zNjUxNTEwMzNdfQ
==
-->